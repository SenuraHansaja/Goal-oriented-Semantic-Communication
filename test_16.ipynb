{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from typing import Sequence, Tuple, Union\n",
    "\n",
    "import lightning as L\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as VisionF\n",
    "from pytorch_lightning import Callback, LightningModule, Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics.functional import accuracy\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.models.resnet import resnet34\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "\n",
    "\n",
    "\n",
    "logger = CSVLogger(\"logs_out\", name=\"encoder_logs\")\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "num_workers = 8\n",
    "max_epochs = 200\n",
    "z_dim = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BarlowTwinsTransform:\n",
    "    def __init__(self, train=True, input_height=224, gaussian_blur=True, jitter_strength=1.0, normalize=None):\n",
    "        self.input_height = input_height\n",
    "        self.gaussian_blur = gaussian_blur\n",
    "        self.jitter_strength = jitter_strength\n",
    "        self.normalize = normalize\n",
    "        self.train = train\n",
    "\n",
    "        color_jitter = transforms.ColorJitter(\n",
    "            0.8 * self.jitter_strength,\n",
    "            0.8 * self.jitter_strength,\n",
    "            0.8 * self.jitter_strength,\n",
    "            0.2 * self.jitter_strength,\n",
    "        )\n",
    "\n",
    "        color_transform = [transforms.RandomApply([color_jitter], p=0.8), transforms.RandomGrayscale(p=0.2)]\n",
    "\n",
    "        if self.gaussian_blur:\n",
    "            kernel_size = int(0.1 * self.input_height)\n",
    "            if kernel_size % 2 == 0:\n",
    "                kernel_size += 1\n",
    "\n",
    "            color_transform.append(transforms.RandomApply([transforms.GaussianBlur(kernel_size=kernel_size)], p=0.5))\n",
    "\n",
    "        self.color_transform = transforms.Compose(color_transform)\n",
    "\n",
    "        if normalize is None:\n",
    "            self.final_transform = transforms.ToTensor()\n",
    "        else:\n",
    "            self.final_transform = transforms.Compose([transforms.ToTensor(), normalize])\n",
    "\n",
    "        self.transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.RandomResizedCrop(self.input_height),\n",
    "                transforms.RandomHorizontalFlip(p=0.5),\n",
    "                self.color_transform,\n",
    "                self.final_transform,\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.finetune_transform = None\n",
    "        if self.train:\n",
    "            self.finetune_transform = transforms.Compose(\n",
    "                [\n",
    "                    transforms.RandomCrop(32, padding=4, padding_mode=\"reflect\"),\n",
    "                    transforms.RandomHorizontalFlip(),\n",
    "                    transforms.ToTensor(),\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            self.finetune_transform = transforms.ToTensor()\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        return self.transform(sample), self.transform(sample), self.finetune_transform(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [01:17<00:00, 2188961.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./cifar-10-python.tar.gz to .\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "def cifar10_normalization():\n",
    "    normalize = transforms.Normalize(\n",
    "        mean=[x / 255.0 for x in [125.3, 123.0, 113.9]], std=[x / 255.0 for x in [63.0, 62.1, 66.7]]\n",
    "    )\n",
    "    return normalize\n",
    "\n",
    "\n",
    "train_transform = BarlowTwinsTransform(\n",
    "    train=True, input_height=32, gaussian_blur=False, jitter_strength=0.5, normalize=cifar10_normalization()\n",
    ")\n",
    "train_dataset = CIFAR10(root=\".\", train=True, download=True, transform=train_transform)\n",
    "\n",
    "val_transform = BarlowTwinsTransform(\n",
    "    train=False, input_height=32, gaussian_blur=False, jitter_strength=0.5, normalize=cifar10_normalization()\n",
    ")\n",
    "val_dataset = CIFAR10(root=\".\", train=False, download=True, transform=train_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, drop_last=True,pin_memory = True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, drop_last=True, pin_memory = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = resnet34()\n",
    "\n",
    "# for CIFAR10, replace the first 7x7 conv with smaller 3x3 conv and remove the first maxpool\n",
    "encoder.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "encoder.maxpool = nn.MaxPool2d(kernel_size=1, stride=1)\n",
    "\n",
    "# replace classification fc layer of Resnet to obtain representations from the backbone\n",
    "encoder.fc = nn.Identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProjectionHead(nn.Module):\n",
    "    def __init__(self, input_dim=1024, hidden_dim=1024, output_dim=1024):\n",
    "        super().__init__()\n",
    "\n",
    "        self.projection_head = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim, bias=True),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim, bias=False),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.projection_head(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn(warmup_steps, step):\n",
    "    if step < warmup_steps:\n",
    "        return float(step) / float(max(1, warmup_steps))\n",
    "    else:\n",
    "        return 1.0\n",
    "\n",
    "\n",
    "def linear_warmup_decay(warmup_steps):\n",
    "    return partial(fn, warmup_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BarlowTwins(LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        encoder,\n",
    "        encoder_out_dim,\n",
    "        num_training_samples,\n",
    "        batch_size,\n",
    "        lambda_coeff=5e-3,\n",
    "        z_dim=128,\n",
    "        learning_rate=1e-4,\n",
    "        warmup_epochs=10,\n",
    "        max_epochs=200,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.projection_head = ProjectionHead(input_dim=encoder_out_dim, hidden_dim=encoder_out_dim, output_dim=z_dim)\n",
    "        self.loss_fn = BarlowTwinsLoss(batch_size=batch_size, lambda_coeff=lambda_coeff, z_dim=z_dim)\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "        self.warmup_epochs = warmup_epochs\n",
    "        self.max_epochs = max_epochs\n",
    "\n",
    "        self.train_iters_per_epoch = num_training_samples // batch_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "    def shared_step(self, batch):\n",
    "        (x1, x2, _), _ = batch\n",
    "\n",
    "        z1 = self.projection_head(self.encoder(x1))\n",
    "        z2 = self.projection_head(self.encoder(x2))\n",
    "\n",
    "        loss, on_diag, off_diag= self.loss_fn(z1, z2)\n",
    "       \n",
    "        self.log(\"on_diag\", on_diag.sum(), on_step=True, on_epoch=True, prog_bar= True, logger=logger)\n",
    "        self.log(\"off_diag\", off_diag.sum(), on_step=True, on_epoch=True, prog_bar= True, logger=logger)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self.shared_step(batch)\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=False)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss = self.shared_step(batch)\n",
    "        self.log(\"val_loss\", loss, on_step=False, on_epoch=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "\n",
    "        warmup_steps = self.train_iters_per_epoch * self.warmup_epochs\n",
    "\n",
    "        scheduler = {\n",
    "            \"scheduler\": torch.optim.lr_scheduler.LambdaLR(\n",
    "                optimizer,\n",
    "                linear_warmup_decay(warmup_steps),\n",
    "            ),\n",
    "            \"interval\": \"step\",\n",
    "            \"frequency\": 1,\n",
    "        }\n",
    "\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OnlineFineTuner(Callback):\n",
    "    def __init__(\n",
    "        self,\n",
    "        encoder_output_dim: int,\n",
    "        num_classes: int,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.optimizer: torch.optim.Optimizer\n",
    "\n",
    "        self.encoder_output_dim = encoder_output_dim\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def on_fit_start(self, trainer: L.Trainer, pl_module: L.LightningModule) -> None:\n",
    "        # add linear_eval layer and optimizer\n",
    "        pl_module.online_finetuner = nn.Linear(self.encoder_output_dim, self.num_classes).to(pl_module.device)\n",
    "        self.optimizer = torch.optim.Adam(pl_module.online_finetuner.parameters(), lr=1e-4)\n",
    "\n",
    "    def extract_online_finetuning_view(\n",
    "        self, batch: Sequence, device: Union[str, torch.device]\n",
    "    ) -> Tuple[Tensor, Tensor]:\n",
    "        (_, _, finetune_view), y = batch\n",
    "        finetune_view = finetune_view.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        return finetune_view, y\n",
    "\n",
    "    def on_train_batch_end(\n",
    "        self,\n",
    "        trainer: L.Trainer,\n",
    "        pl_module: L.LightningModule,\n",
    "        outputs: Sequence,\n",
    "        batch: Sequence,\n",
    "        batch_idx: int,\n",
    "    ) -> None:\n",
    "        x, y = self.extract_online_finetuning_view(batch, pl_module.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            feats = pl_module(x)\n",
    "\n",
    "        feats = feats.detach()\n",
    "        preds = pl_module.online_finetuner(feats)\n",
    "        loss = F.cross_entropy(preds, y)\n",
    "\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        acc = accuracy(F.softmax(preds, dim=1), y, task=\"multiclass\", num_classes=10)\n",
    "        pl_module.log(\"online_train_acc\", acc, on_step=True, on_epoch=False)\n",
    "        pl_module.log(\"online_train_loss\", loss, on_step=True, on_epoch=False)\n",
    "\n",
    "    def on_validation_batch_end(\n",
    "        self,\n",
    "        trainer: L.Trainer,\n",
    "        pl_module: L.LightningModule,\n",
    "        outputs: Sequence,\n",
    "        batch: Sequence,\n",
    "        batch_idx: int,\n",
    "    ) -> None:\n",
    "        x, y = self.extract_online_finetuning_view(batch, pl_module.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            feats = pl_module(x)\n",
    "\n",
    "        feats = feats.detach()\n",
    "        preds = pl_module.online_finetuner(feats)\n",
    "        loss = F.cross_entropy(preds, y)\n",
    "\n",
    "        acc = accuracy(F.softmax(preds, dim=1), y, task=\"multiclass\", num_classes=10)\n",
    "        pl_module.log(\"online_val_acc\", acc, on_step=False, on_epoch=True, sync_dist=True)\n",
    "        pl_module.log(\"online_val_loss\", loss, on_step=False, on_epoch=True, sync_dist=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BarlowTwinsLoss(nn.Module):\n",
    "    def __init__(self, batch_size, lambda_coeff=5e-3, z_dim=128):\n",
    "        super().__init__()\n",
    "\n",
    "        self.z_dim = z_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.lambda_coeff = lambda_coeff\n",
    "\n",
    "    def off_diagonal_ele(self, x):\n",
    "        # taken from: https://github.com/facebookresearch/barlowtwins/blob/main/main.py\n",
    "        # return a flattened view of the off-diagonal elements of a square matrix\n",
    "        n, m = x.shape\n",
    "        assert n == m\n",
    "        return x.flatten()[:-1].view(n - 1, n + 1)[:, 1:].flatten()\n",
    "\n",
    "    def forward(self, z1, z2):\n",
    "        # N x D, where N is the batch size and D is output dim of projection head\n",
    "        z1_norm = (z1 - torch.mean(z1, dim=0)) / torch.std(z1, dim=0)\n",
    "        z2_norm = (z2 - torch.mean(z2, dim=0)) / torch.std(z2, dim=0)\n",
    "\n",
    "        cross_corr = torch.mm(z1_norm.T, z2_norm) / self.batch_size\n",
    "\n",
    "        on_diag = torch.diagonal(cross_corr).add_(-1).pow_(2).sum()\n",
    "        off_diag = self.off_diagonal_ele(cross_corr).pow_(2).sum()\n",
    "\n",
    "        return on_diag + self.lambda_coeff * off_diag, on_diag, off_diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ModelCheckpoint(save_last=True, save_top_k=-1, monitor=None) will duplicate the last checkpoint saved.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ifire/.local/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:617: UserWarning: Checkpoint directory logs_out/encoder_logs/version_0/checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name            | Type            | Params\n",
      "----------------------------------------------------\n",
      "0 | encoder         | ResNet          | 21.3 M\n",
      "1 | projection_head | ProjectionHead  | 787 K \n",
      "2 | loss_fn         | BarlowTwinsLoss | 0     \n",
      "----------------------------------------------------\n",
      "22.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "22.1 M    Total params\n",
      "88.260    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a18f89f8109434ab2c38237daddd98f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    }
   ],
   "source": [
    "encoder_out_dim = 512\n",
    "\n",
    "model = BarlowTwins(\n",
    "    encoder=encoder,\n",
    "    encoder_out_dim=encoder_out_dim,\n",
    "    num_training_samples=len(train_dataset),\n",
    "    batch_size=batch_size,\n",
    "    z_dim=z_dim,\n",
    ")\n",
    "\n",
    "online_finetuner = OnlineFineTuner(encoder_output_dim=encoder_out_dim, num_classes=10)\n",
    "checkpoint_callback = ModelCheckpoint(every_n_epochs=100, save_top_k=-1, save_last=True)\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=max_epochs,\n",
    "    accelerator=\"auto\",\n",
    "    devices=1 if torch.cuda.is_available() else None,  # limiting got iPython runs\n",
    "    callbacks=[#online_finetuner,\n",
    "        checkpoint_callback],\n",
    "    logger=logger\n",
    ")\n",
    "\n",
    "# uncomment this to train the model\n",
    "# this is done for the tutorial so that the notebook compiles\n",
    "trainer.fit(model, train_loader,)#val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class classifire(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=512, out_features=1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=1024, out_features=1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=1024, out_features=10),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x:torch.Tensor):\n",
    "        x = self.block(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifire_model = classifire()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_optimizer = torch.optim.Adam(classifire_model.parameters(), lr = 1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(ai_optimizer, 200)\n",
    "goai_loss_fn = nn.CrossEntropyLoss()\n",
    "# ai_optimizer = torch.optim.SGD(classifire_model.parameters(), lr=1e-3,\n",
    "#                                 momentum=0.9, weight_decay=5e-4)\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(ai_optimizer, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss: 0.6874 Acc: 0.7728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Loss: 0.6142 Acc: 0.7869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Loss: 0.5975 Acc: 0.7927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 Loss: 0.5900 Acc: 0.7939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 Loss: 0.5756 Acc: 0.7970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Loss: 0.5747 Acc: 0.7978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 Loss: 0.5660 Acc: 0.8009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 Loss: 0.5612 Acc: 0.8005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 Loss: 0.5562 Acc: 0.8047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 Loss: 0.5460 Acc: 0.8074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Loss: 0.5505 Acc: 0.8041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 Loss: 0.5454 Acc: 0.8070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 Loss: 0.5412 Acc: 0.8080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 Loss: 0.5387 Acc: 0.8085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 Loss: 0.5370 Acc: 0.8085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 Loss: 0.5295 Acc: 0.8133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 Loss: 0.5285 Acc: 0.8120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 Loss: 0.5282 Acc: 0.8128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 Loss: 0.5257 Acc: 0.8123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 Loss: 0.5175 Acc: 0.8159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 Loss: 0.5176 Acc: 0.8151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21 Loss: 0.5188 Acc: 0.8163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22 Loss: 0.5162 Acc: 0.8155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23 Loss: 0.5124 Acc: 0.8184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24 Loss: 0.5112 Acc: 0.8174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25 Loss: 0.5093 Acc: 0.8191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26 Loss: 0.5014 Acc: 0.8205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27 Loss: 0.5028 Acc: 0.8207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28 Loss: 0.4966 Acc: 0.8232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29 Loss: 0.4982 Acc: 0.8212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30 Loss: 0.4976 Acc: 0.8224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31 Loss: 0.4980 Acc: 0.8223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32 Loss: 0.4926 Acc: 0.8242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33 Loss: 0.4880 Acc: 0.8255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34 Loss: 0.4900 Acc: 0.8264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35 Loss: 0.4834 Acc: 0.8272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36 Loss: 0.4872 Acc: 0.8273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37 Loss: 0.4815 Acc: 0.8267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38 Loss: 0.4883 Acc: 0.8266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39 Loss: 0.4757 Acc: 0.8310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40 Loss: 0.4754 Acc: 0.8311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41 Loss: 0.4756 Acc: 0.8309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42 Loss: 0.4712 Acc: 0.8332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43 Loss: 0.4730 Acc: 0.8306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44 Loss: 0.4727 Acc: 0.8294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 45 Loss: 0.4710 Acc: 0.8321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46 Loss: 0.4668 Acc: 0.8335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 47 Loss: 0.4618 Acc: 0.8352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48 Loss: 0.4625 Acc: 0.8350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 49 Loss: 0.4597 Acc: 0.8354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50 Loss: 0.4610 Acc: 0.8351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 51 Loss: 0.4600 Acc: 0.8359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 52 Loss: 0.4560 Acc: 0.8364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 53 Loss: 0.4527 Acc: 0.8373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 54 Loss: 0.4548 Acc: 0.8380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 55 Loss: 0.4487 Acc: 0.8390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 56 Loss: 0.4489 Acc: 0.8406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 57 Loss: 0.4507 Acc: 0.8387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 58 Loss: 0.4482 Acc: 0.8384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 59 Loss: 0.4452 Acc: 0.8420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 60 Loss: 0.4462 Acc: 0.8400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 61 Loss: 0.4394 Acc: 0.8427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 62 Loss: 0.4399 Acc: 0.8418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 63 Loss: 0.4364 Acc: 0.8448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 64 Loss: 0.4357 Acc: 0.8453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 65 Loss: 0.4349 Acc: 0.8445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 66 Loss: 0.4327 Acc: 0.8468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 67 Loss: 0.4337 Acc: 0.8447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 68 Loss: 0.4307 Acc: 0.8468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 69 Loss: 0.4318 Acc: 0.8448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 70 Loss: 0.4351 Acc: 0.8447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 71 Loss: 0.4338 Acc: 0.8450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 72 Loss: 0.4221 Acc: 0.8501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 73 Loss: 0.4175 Acc: 0.8508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 74 Loss: 0.4246 Acc: 0.8478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 75 Loss: 0.4212 Acc: 0.8511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 76 Loss: 0.4231 Acc: 0.8498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 77 Loss: 0.4188 Acc: 0.8501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 78 Loss: 0.4131 Acc: 0.8526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 79 Loss: 0.4193 Acc: 0.8518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 80 Loss: 0.4126 Acc: 0.8525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 81 Loss: 0.4152 Acc: 0.8519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 82 Loss: 0.4152 Acc: 0.8537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 83 Loss: 0.4056 Acc: 0.8555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 84 Loss: 0.4077 Acc: 0.8552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 85 Loss: 0.4138 Acc: 0.8539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 86 Loss: 0.4094 Acc: 0.8547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 87 Loss: 0.4073 Acc: 0.8563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 88 Loss: 0.4031 Acc: 0.8556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 89 Loss: 0.4093 Acc: 0.8541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 90 Loss: 0.4070 Acc: 0.8554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 91 Loss: 0.4009 Acc: 0.8583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 92 Loss: 0.4024 Acc: 0.8571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 93 Loss: 0.4013 Acc: 0.8577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 94 Loss: 0.3966 Acc: 0.8586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 95 Loss: 0.3994 Acc: 0.8597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 96 Loss: 0.3997 Acc: 0.8576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 97 Loss: 0.4007 Acc: 0.8572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 98 Loss: 0.3958 Acc: 0.8602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [46:20<00:00, 27.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 99 Loss: 0.3893 Acc: 0.8620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "running_loss = 0.0\n",
    "\n",
    "running_corrects = 0\n",
    "epochs =  100\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    for batch in train_loader:\n",
    "        (img1, img2, _), label = batch\n",
    "        img1 = img1.to('cuda')\n",
    "        model = model.to('cuda')\n",
    "        label = label.to('cuda')\n",
    "        model.eval()\n",
    "        classifire_model.to('cuda')\n",
    "        classifire_model.train()\n",
    "\n",
    "        encoder_out = model.forward(img1)\n",
    "        input_to_goai = torch.unsqueeze(encoder_out, dim=1)             ### these unsuqeese is done to make the data follow NCHW pattern which is used inside the pytorch as a data format\n",
    "        input_to_goai = torch.unsqueeze(input_to_goai, dim=1)\n",
    "        #y_pred = GOAI_model(encoder_out)\n",
    "        \n",
    "       # GOAI_model.to('cuda')\n",
    "        y_pred = classifire_model(input_to_goai)\n",
    "        _, preds = torch.max(y_pred, 1)\n",
    "        \n",
    "        loss = goai_loss_fn(y_pred, label)\n",
    "        ai_optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        ai_optimizer.step()\n",
    "        running_loss += loss.item() * batch_size\n",
    "        running_corrects += torch.sum(preds == label.data)\n",
    "    scheduler.step()\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    epoch_acc = running_corrects.double() / len(train_loader.dataset)\n",
    "\n",
    "    print('Epoch: {} Loss: {:.4f} Acc: {:.4f}'.format(epoch,  epoch_loss, epoch_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 79 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.inference_mode():\n",
    "    for batch in val_loader:\n",
    "         (img1, img2, _), label = batch\n",
    "         model.eval()\n",
    "         classifire_model.eval()\n",
    "         model.to('cpu')\n",
    "         classifire_model.to('cpu')\n",
    "    \n",
    "         encoder_out = model.forward(img1)\n",
    "         input_to_goai = torch.unsqueeze(encoder_out, dim=1)             ### these unsuqeese is done to make the data follow NCHW pattern which is used inside the pytorch as a data format\n",
    "         input_to_goai = torch.unsqueeze(input_to_goai, dim=1)\n",
    "         y_pred = classifire_model(input_to_goai)\n",
    "         _, preds = torch.max(y_pred.data, 1)\n",
    "         total += label.size(0)\n",
    "         correct += (preds == label).sum().item()\n",
    "# epoch_acc = running_corrects.double() / len(val_loader.dataset)\n",
    "# print('Acc: {:.4f}'.format(epoch_acc))\n",
    "print('Accuracy of the network on the test images: %d %%' % (100 * correct / total))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class classifire(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=512, out_features=1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=1024, out_features=1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=1024, out_features=1024),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(in_features=1024, out_features=10)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x:torch.Tensor):\n",
    "        x = self.block(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ifire/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/ifire/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "##end to end ml\n",
    "## use resent-9 as per planned before\n",
    "GOAI_model = models.resnet18(pretrained=False).to('cuda')\n",
    "GOAI_model.conv1 = nn.Conv2d(1, 64, kernel_size=(3,3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "num_features = GOAI_model.fc.in_features\n",
    "GOAI_model.fc = nn.Linear(num_features, 10)\n",
    "\n",
    "ai_optimizer = torch.optim.Adam(GOAI_model.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(ai_optimizer, 100)\n",
    "goai_loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifire_model = classifire()\n",
    "# ai_optimizer = torch.optim.Adam(classifire_model.parameters(), lr = 1e-4)\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(ai_optimizer, 100)\n",
    "# goai_loss_fn = nn.CrossEntropyLoss()\n",
    "# # ai_optimizer = torch.optim.SGD(classifire_model.parameters(), lr=1e-3,\n",
    "# #                                 momentum=0.9, weight_decay=5e-4)\n",
    "# # scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(ai_optimizer, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss: 0.8484 Acc: 0.7285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Loss: 0.6832 Acc: 0.7724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Loss: 0.6537 Acc: 0.7797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 Loss: 0.6425 Acc: 0.7807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 Loss: 0.6239 Acc: 0.7882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Loss: 0.6117 Acc: 0.7899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 Loss: 0.6011 Acc: 0.7931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 Loss: 0.5982 Acc: 0.7931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 Loss: 0.5975 Acc: 0.7950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 Loss: 0.5881 Acc: 0.7962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Loss: 0.5738 Acc: 0.8028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 Loss: 0.5696 Acc: 0.8027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 Loss: 0.5673 Acc: 0.8023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 Loss: 0.5513 Acc: 0.8102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 Loss: 0.5498 Acc: 0.8083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 Loss: 0.5427 Acc: 0.8130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 Loss: 0.5421 Acc: 0.8117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 Loss: 0.5350 Acc: 0.8142\n"
     ]
    }
   ],
   "source": [
    "\n",
    "running_loss = 0.0\n",
    "\n",
    "running_corrects = 0\n",
    "epochs =  100\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    for batch in train_loader:\n",
    "        (img1, img2, _), label = batch\n",
    "        img1 = img1.to('cuda')\n",
    "        model = model.to('cuda')\n",
    "        label = label.to('cuda')\n",
    "        model.eval()\n",
    "        classifire_model.to('cuda')\n",
    "        classifire_model.train()\n",
    "\n",
    "        encoder_out = model.forward(img1)\n",
    "        input_to_goai = torch.unsqueeze(encoder_out, dim=1)             ### these unsuqeese is done to make the data follow NCHW pattern which is used inside the pytorch as a data format\n",
    "        input_to_goai = torch.unsqueeze(input_to_goai, dim=1)\n",
    "        GOAI_model.to('cuda')\n",
    "        y_pred = GOAI_model(input_to_goai)\n",
    "        \n",
    "        #GOAI_model.to('cuda')\n",
    "        #y_pred = classifire_model(input_to_goai)\n",
    "        _, preds = torch.max(y_pred, 1)\n",
    "        \n",
    "        loss = goai_loss_fn(y_pred, label)\n",
    "        ai_optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        ai_optimizer.step()\n",
    "        running_loss += loss.item() * batch_size\n",
    "        running_corrects += torch.sum(preds == label.data)\n",
    "    scheduler.step()\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    epoch_acc = running_corrects.double() / len(train_loader.dataset)\n",
    "\n",
    "    print('Epoch: {} Loss: {:.4f} Acc: {:.4f}'.format(epoch,  epoch_loss, epoch_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 79 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.inference_mode():\n",
    "    for batch in val_loader:\n",
    "         (img1, img2, _), label = batch\n",
    "         model.eval()\n",
    "         classifire_model.eval()\n",
    "         model.to('cpu')\n",
    "         classifire_model.to('cpu')\n",
    "    \n",
    "         encoder_out = model.forward(img1)\n",
    "         input_to_goai = torch.unsqueeze(encoder_out, dim=1)             ### these unsuqeese is done to make the data follow NCHW pattern which is used inside the pytorch as a data format\n",
    "         input_to_goai = torch.unsqueeze(input_to_goai, dim=1)\n",
    "         y_pred = classifire_model(input_to_goai)\n",
    "         _, preds = torch.max(y_pred.data, 1)\n",
    "         total += label.size(0)\n",
    "         correct += (preds == label).sum().item()\n",
    "# epoch_acc = running_corrects.double() / len(val_loader.dataset)\n",
    "# print('Acc: {:.4f}'.format(epoch_acc))\n",
    "print('Accuracy of the network on the test images: %d %%' % (100 * correct / total))     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
