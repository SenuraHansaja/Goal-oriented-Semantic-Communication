{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ifire/.local/lib/python3.10/site-packages/pkg_resources/__init__.py:116: PkgResourcesDeprecationWarning: 1.1build1 is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n",
      "/home/ifire/.local/lib/python3.10/site-packages/pkg_resources/__init__.py:116: PkgResourcesDeprecationWarning: 1.1build1 is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "from typing import Sequence, Tuple, Union\n",
    "\n",
    "import lightning as L\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as VisionF\n",
    "from pytorch_lightning import Callback, LightningModule, Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics.functional import accuracy\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.models.resnet import resnet34\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "\n",
    "\n",
    "\n",
    "logger = CSVLogger(\"logs_out\", name=\"encoder_logs\")\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "num_workers = 8\n",
    "max_epochs = 200\n",
    "z_dim = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BarlowTwinsTransform:\n",
    "    def __init__(self, train=True, input_height=224, gaussian_blur=True, jitter_strength=1.0, normalize=None):\n",
    "        self.input_height = input_height\n",
    "        self.gaussian_blur = gaussian_blur\n",
    "        self.jitter_strength = jitter_strength\n",
    "        self.normalize = normalize\n",
    "        self.train = train\n",
    "\n",
    "        color_jitter = transforms.ColorJitter(\n",
    "            0.8 * self.jitter_strength,\n",
    "            0.8 * self.jitter_strength,\n",
    "            0.8 * self.jitter_strength,\n",
    "            0.2 * self.jitter_strength,\n",
    "        )\n",
    "\n",
    "        color_transform = [transforms.RandomApply([color_jitter], p=0.8), transforms.RandomGrayscale(p=0.2)]\n",
    "\n",
    "        if self.gaussian_blur:\n",
    "            kernel_size = int(0.1 * self.input_height)\n",
    "            if kernel_size % 2 == 0:\n",
    "                kernel_size += 1\n",
    "\n",
    "            color_transform.append(transforms.RandomApply([transforms.GaussianBlur(kernel_size=kernel_size)], p=0.5))\n",
    "\n",
    "        self.color_transform = transforms.Compose(color_transform)\n",
    "\n",
    "        if normalize is None:\n",
    "            self.final_transform = transforms.ToTensor()\n",
    "        else:\n",
    "            self.final_transform = transforms.Compose([transforms.ToTensor(), normalize])\n",
    "\n",
    "        self.transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.RandomResizedCrop(self.input_height),\n",
    "                transforms.RandomHorizontalFlip(p=0.5),\n",
    "                self.color_transform,\n",
    "                self.final_transform,\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.finetune_transform = None\n",
    "        if self.train:\n",
    "            self.finetune_transform = transforms.Compose(\n",
    "                [\n",
    "                    transforms.RandomCrop(32, padding=4, padding_mode=\"reflect\"),\n",
    "                    transforms.RandomHorizontalFlip(),\n",
    "                    transforms.ToTensor(),\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            self.finetune_transform = transforms.ToTensor()\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        return self.transform(sample), self.transform(sample), self.finetune_transform(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [25:02<00:00, 113478.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./cifar-10-python.tar.gz to .\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "def cifar10_normalization():\n",
    "    normalize = transforms.Normalize(\n",
    "        mean=[x / 255.0 for x in [125.3, 123.0, 113.9]], std=[x / 255.0 for x in [63.0, 62.1, 66.7]]\n",
    "    )\n",
    "    return normalize\n",
    "\n",
    "\n",
    "train_transform = BarlowTwinsTransform(\n",
    "    train=True, input_height=32, gaussian_blur=False, jitter_strength=0.5, normalize=cifar10_normalization()\n",
    ")\n",
    "train_dataset = CIFAR10(root=\".\", train=True, download=True, transform=train_transform)\n",
    "\n",
    "val_transform = BarlowTwinsTransform(\n",
    "    train=False, input_height=32, gaussian_blur=False, jitter_strength=0.5, normalize=cifar10_normalization()\n",
    ")\n",
    "val_dataset = CIFAR10(root=\".\", train=False, download=True, transform=train_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, drop_last=True,pin_memory = True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, drop_last=True, pin_memory = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BarlowTwinsLoss(nn.Module):\n",
    "    def __init__(self, batch_size, lambda_coeff=5e-3, z_dim=128):\n",
    "        super().__init__()\n",
    "\n",
    "        self.z_dim = z_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.lambda_coeff = lambda_coeff\n",
    "\n",
    "    def off_diagonal_ele(self, x):\n",
    "        # taken from: https://github.com/facebookresearch/barlowtwins/blob/main/main.py\n",
    "        # return a flattened view of the off-diagonal elements of a square matrix\n",
    "        n, m = x.shape\n",
    "        assert n == m\n",
    "        return x.flatten()[:-1].view(n - 1, n + 1)[:, 1:].flatten()\n",
    "\n",
    "    def forward(self, z1, z2):\n",
    "        # N x D, where N is the batch size and D is output dim of projection head\n",
    "        z1_norm = (z1 - torch.mean(z1, dim=0)) / torch.std(z1, dim=0)\n",
    "        z2_norm = (z2 - torch.mean(z2, dim=0)) / torch.std(z2, dim=0)\n",
    "\n",
    "        cross_corr = torch.mm(z1_norm.T, z2_norm) / self.batch_size\n",
    "\n",
    "        on_diag = torch.diagonal(cross_corr).add_(-1).pow_(2).sum()\n",
    "        off_diag = self.off_diagonal_ele(cross_corr).pow_(2).sum()\n",
    "\n",
    "        return on_diag + self.lambda_coeff * off_diag, on_diag, off_diag"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
